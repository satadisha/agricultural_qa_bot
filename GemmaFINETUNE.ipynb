{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Run if the code block to train the model is not working and showing errors.\n",
        "# !pip install --upgrade unsloth transformers torch accelerate bitsandbytes trl\n",
        "!pip install vllm -q"
      ],
      "metadata": {
        "id": "_iIFkpJvEmTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FN4kjPXJ1bt"
      },
      "outputs": [],
      "source": [
        "# Setting up. Installing unsloth\n",
        "%%capture\n",
        "!pip install unsloth -q\n",
        "!pip install --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access your hugging face API\n",
        "from google.colab import userdata\n",
        "hf_token = userdata.get() # Use hugging face api key (Or colab secrets)"
      ],
      "metadata": {
        "id": "XtZHdYQvL4NQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access your weights and biases API\n",
        "import wandb\n",
        "from google.colab import userdata\n",
        "wb_token = userdata.get()"
      ],
      "metadata": {
        "id": "RMeMDVcQL5aE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates a new project to track experiemnts and fine-tuning process\n",
        "run = wandb.init(\n",
        "    project='',\n",
        "    job_type=\"training\",\n",
        "    anonymous=\"allow\"\n",
        ")"
      ],
      "metadata": {
        "id": "fZBE6DkvUUlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading model and tokenizer\n",
        "from unsloth import FastLanguageModel\n",
        "\n",
        "max_seq_length = 1024\n",
        "dtype = None\n",
        "load_in_4bit = True\n",
        "\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/gemma-7b-it-bnb-4bit\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    token = hf_token\n",
        ")"
      ],
      "metadata": {
        "id": "lAreAMYjU9ht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Data\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"json\", data_files=\"QA_finetuned.jsonl\", split=\"train\")\n",
        "\n",
        "train_dataset = dataset.select(range(430))\n",
        "val_dataset = dataset.select(range(430, 538))\n",
        "\n",
        "# Example\n",
        "print(train_dataset)\n",
        "print(val_dataset)"
      ],
      "metadata": {
        "id": "kkntcttB4_i-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EOS_TOKEN = tokenizer.eos_token  # Must add EOS_TOKEN\n",
        "\n",
        "def format_example(example):\n",
        "  \"\"\"Concatenates each example in the dataset into a single string. Adds a token that tracks the end of a sentence\"\"\"\n",
        "  return {\n",
        "      \"text\": f\"{example['instruction']}\\n\\n{example['response']}{EOS_TOKEN}\"\n",
        "  }\n",
        "\n",
        "train_dataset = train_dataset.map(format_example)\n",
        "val_dataset = val_dataset.map(format_example)\n",
        "\n",
        "print(train_dataset)\n",
        "print(val_dataset)"
      ],
      "metadata": {
        "id": "Cb_qsCDB6NK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the model. Adding low rank adapters to the model\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=16,\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\",\n",
        "    ],\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0,\n",
        "    bias=\"none\",\n",
        "    use_gradient_checkpointing=\"unsloth\",\n",
        "    random_state=3407,\n",
        "    use_rslora=False,\n",
        "    loftq_config=None\n",
        ")"
      ],
      "metadata": {
        "id": "REaKSWJ58omD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the training arguments and the trainer\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    dataset_num_proc=2,\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=1,\n",
        "        gradient_accumulation_steps=4,\n",
        "        num_train_epochs=3,\n",
        "        # Use num_train_epochs = 1, warmup_ratio for full training runs!\n",
        "        learning_rate=2e-4,\n",
        "        fp16=False,\n",
        "        bf16=True,\n",
        "        logging_steps=10,\n",
        "        save_strategy=\"besr\",\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=0.01,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        output_dir=\"./results\",\n",
        "        load_best_model_at_end=True\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "bdQJQV2d9sNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training; run line to start training\n",
        "trainer_stats = trainer.train()"
      ],
      "metadata": {
        "id": "XBydQnkS-9bG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel\n",
        "\n",
        "# Step 1: Define your local folder\n",
        "new_model_local = \"\"\n",
        "\n",
        "# Step 2: Merge the LoRA adapters into base model\n",
        "model = model.merge_and_unload()  # This must come *before* save_pretrained\n",
        "\n",
        "# Step 3: Save to disk\n",
        "model.save_pretrained(new_model_local, safe_serialization=True)\n",
        "tokenizer.save_pretrained(new_model_local)"
      ],
      "metadata": {
        "id": "Q5PrKFfPhp-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Log into huggingface hub\n",
        "from huggingface_hub import login\n",
        "login()"
      ],
      "metadata": {
        "id": "lErPBtI2dtZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Push to huggingface hub\n",
        "model.push_to_hub(\"\")\n",
        "tokenizer.push_to_hub(\"\")"
      ],
      "metadata": {
        "id": "AOXtB4FM8wAB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}